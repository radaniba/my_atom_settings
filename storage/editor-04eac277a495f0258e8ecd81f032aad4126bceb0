{"mode":"editor","version":1,"windowDimensions":{"x":0,"y":22,"width":1280,"height":732},"syntax":{"deserializer":"Syntax","grammarOverridesByPath":{}},"project":{"path":"/Users/Rad/Documents/Scripts","buffers":[{"text":"#!/usr/bin/env python\nimport pysam\nimport argparse\nimport sys\n\nparser = argparse.ArgumentParser(description='Filter a paired-end BAM file such that both reads have MAPQs >= a threshold.')\nparser.add_argument('threshold', type=int, help=\"MAPQ threshold\")\nparser.add_argument('input_file', help=\"input file name\")\nparser.add_argument('output_file', help=\"output file name\")\nargs = parser.parse_args()\nif(args.threshold == None or args.input_file == None or args.output_file == None) :\n    parser.print_help()\n    sys.exit()\n\n#One could look at the file name too see if we're dealing with a SAM or BAM file, but this is simpler\nifile = pysam.Samfile(args.input_file, \"rb\")\nofile = pysam.Samfile(args.output_file, \"wb\", template=ifile)\n\n#iterate\nwhile(1) :\n    try :\n        r1 = ifile.next()\n        r2 = ifile.next()\n    except :\n        break\n\n    if(r1.mapq >= int(args.threshold) and r2.mapq >= int(args.threshold)) :\n        ofile.write(r1)\n        ofile.write(r2)\n\nifile.close()\nofile.close()\n\n\n\n\n\ndef print_format_table():\n    \"\"\"\n    prints table of formatted text format options\n    \"\"\"\n    for style in xrange(8):\n        for fg in xrange(30, 38):\n            s1 = ''\n            for bg in xrange(40, 48):\n                format = ';'.join([str(style), str(fg), str(bg)])\n                s1 += '\\x1b[%sm %s \\x1b[0m' % (format, format)\n            print s1\n        print '\\n'\n\n#print(\"BEFORE\")\n\n#print_format_table()\n\n#print(\"AFTER\")\n\n\ndef create_samples_list_from_location(path_to_fastq):\n\n    \"\"\"\n    Parse Fastq files directory and get the samples names, push them to list\n    \"\"\"\n    samples = []\n    for root, dirs, files in os.walk(path_to_fastq):\n        for file in files:\n            if file.endswith(\"_L001_R1_L01.fastq\"):\n                 sample_id = file.split(\"_L001_R1\")[0]\n                 samples.append(sample_id)\n    #return samples\n    print \"samples:\"\n    for sample in samples:\n        print \" \"+sample+\":\"\n        print \"   fastq_file1:\"+os.path.join(path_to_fastq,sample)+\"_L001_R1_L01.fastq\"\n        print \"   fastq_file2:\"+os.path.join(path_to_fastq,sample)+\"_L001_R2_L01.fastq\"\n\n\n\n#create_samples_list_from_location(\"/Users/Rad/Documents/Scripts/test_python/fastq\")\n","markers":{"markers":{"1":{"id":1,"range":[[56,0],[56,0]],"tailed":false,"reversed":true,"valid":true,"invalidate":"never","persistent":true,"properties":{"type":"selection","editorId":75,"preserveFolds":true,"goalBufferRange":null},"deserializer":"Marker"}},"deserializer":"MarkerManager"},"history":{"undoStack":[{"patches":[{"oldRange":[[6,0],[6,0]],"newRange":[[6,0],[7,0]],"oldText":"","newText":"\n","normalizeLineEndings":{},"markerPatches":{},"deserializer":"BufferPatch"},{"oldRange":[[7,0],[7,0]],"newRange":[[7,0],[7,0]],"oldText":"","newText":"","normalizeLineEndings":true,"markerPatches":{},"deserializer":"BufferPatch"}],"deserializer":"Transaction"},{"patches":[{"oldRange":[[7,0],[7,0]],"newRange":[[7,0],[8,0]],"oldText":"","newText":"\n","normalizeLineEndings":{},"markerPatches":{},"deserializer":"BufferPatch"},{"oldRange":[[8,0],[8,0]],"newRange":[[8,0],[8,0]],"oldText":"","newText":"","normalizeLineEndings":true,"markerPatches":{},"deserializer":"BufferPatch"}],"deserializer":"Transaction"},{"patches":[{"oldRange":[[8,0],[8,0]],"newRange":[[8,0],[9,0]],"oldText":"","newText":"\n","normalizeLineEndings":{},"markerPatches":{},"deserializer":"BufferPatch"},{"oldRange":[[9,0],[9,0]],"newRange":[[9,0],[9,0]],"oldText":"","newText":"","normalizeLineEndings":true,"markerPatches":{},"deserializer":"BufferPatch"}],"deserializer":"Transaction"},{"patches":[{"oldRange":[[9,0],[9,0]],"newRange":[[9,0],[10,0]],"oldText":"","newText":"\n","normalizeLineEndings":{},"markerPatches":{},"deserializer":"BufferPatch"},{"oldRange":[[10,0],[10,0]],"newRange":[[10,0],[10,0]],"oldText":"","newText":"","normalizeLineEndings":true,"markerPatches":{},"deserializer":"BufferPatch"}],"deserializer":"Transaction"},{"patches":[{"oldRange":[[10,0],[10,0]],"newRange":[[10,0],[11,0]],"oldText":"","newText":"\n","normalizeLineEndings":{},"markerPatches":{},"deserializer":"BufferPatch"},{"oldRange":[[11,0],[11,0]],"newRange":[[11,0],[11,0]],"oldText":"","newText":"","normalizeLineEndings":true,"markerPatches":{},"deserializer":"BufferPatch"}],"deserializer":"Transaction"},{"patches":[{"oldRange":[[6,0],[6,0]],"newRange":[[6,0],[9,61]],"oldText":"","newText":"def my_fetch_callback( alignment ):\n    print str(alignment)\n\nsamfile.fetch( 'seq1', 10, 20, callback = my_fetch_callback )","normalizeLineEndings":{},"markerPatches":{},"deserializer":"BufferPatch"}],"deserializer":"Transaction"},{"patches":[{"oldRange":[[6,0],[6,0]],"newRange":[[6,0],[7,0]],"oldText":"","newText":"\n","normalizeLineEndings":{},"markerPatches":{},"deserializer":"BufferPatch"},{"oldRange":[[7,0],[7,0]],"newRange":[[7,0],[7,0]],"oldText":"","newText":"","normalizeLineEndings":true,"markerPatches":{},"deserializer":"BufferPatch"}],"deserializer":"Transaction"},{"patches":[{"id":1,"oldParams":{"tailed":false},"newParams":{"tailed":true},"deserializer":"MarkerPatch"},{"id":1,"oldParams":{"reversed":false,"range":[[10,21],[10,21]]},"newParams":{"reversed":true,"range":[[10,20],[10,21]]},"deserializer":"MarkerPatch"},{"oldRange":[[10,20],[10,21]],"newRange":[[10,20],[10,20]],"oldText":"'","newText":"","normalizeLineEndings":true,"markerPatches":{},"deserializer":"BufferPatch"},{"id":1,"oldParams":{"tailed":true},"newParams":{"tailed":false},"deserializer":"MarkerPatch"}],"deserializer":"Transaction"},{"patches":[{"id":1,"oldParams":{"tailed":false},"newParams":{"tailed":true},"deserializer":"MarkerPatch"},{"id":1,"oldParams":{"range":[[10,20],[10,20]]},"newParams":{"range":[[10,19],[10,20]]},"deserializer":"MarkerPatch"},{"oldRange":[[10,19],[10,20]],"newRange":[[10,19],[10,19]],"oldText":"1","newText":"","normalizeLineEndings":true,"markerPatches":{},"deserializer":"BufferPatch"},{"id":1,"oldParams":{"tailed":true},"newParams":{"tailed":false},"deserializer":"MarkerPatch"}],"deserializer":"Transaction"},{"patches":[{"id":1,"oldParams":{"tailed":false},"newParams":{"tailed":true},"deserializer":"MarkerPatch"},{"id":1,"oldParams":{"range":[[10,19],[10,19]]},"newParams":{"range":[[10,18],[10,19]]},"deserializer":"MarkerPatch"},{"oldRange":[[10,18],[10,19]],"newRange":[[10,18],[10,18]],"oldText":"q","newText":"","normalizeLineEndings":true,"markerPatches":{},"deserializer":"BufferPatch"},{"id":1,"oldParams":{"tailed":true},"newParams":{"tailed":false},"deserializer":"MarkerPatch"}],"deserializer":"Transaction"},{"patches":[{"id":1,"oldParams":{"tailed":false},"newParams":{"tailed":true},"deserializer":"MarkerPatch"},{"id":1,"oldParams":{"range":[[10,18],[10,18]]},"newParams":{"range":[[10,17],[10,18]]},"deserializer":"MarkerPatch"},{"oldRange":[[10,17],[10,18]],"newRange":[[10,17],[10,17]],"oldText":"e","newText":"","normalizeLineEndings":true,"markerPatches":{},"deserializer":"BufferPatch"},{"id":1,"oldParams":{"tailed":true},"newParams":{"tailed":false},"deserializer":"MarkerPatch"}],"deserializer":"Transaction"},{"patches":[{"id":1,"oldParams":{"tailed":false},"newParams":{"tailed":true},"deserializer":"MarkerPatch"},{"id":1,"oldParams":{"range":[[10,17],[10,17]]},"newParams":{"range":[[10,16],[10,17]]},"deserializer":"MarkerPatch"},{"oldRange":[[10,16],[10,17]],"newRange":[[10,16],[10,16]],"oldText":"s","newText":"","normalizeLineEndings":true,"markerPatches":{},"deserializer":"BufferPatch"},{"id":1,"oldParams":{"tailed":true},"newParams":{"tailed":false},"deserializer":"MarkerPatch"}],"deserializer":"Transaction"},{"patches":[{"id":1,"oldParams":{"tailed":false},"newParams":{"tailed":true},"deserializer":"MarkerPatch"},{"id":1,"oldParams":{"range":[[10,16],[10,16]]},"newParams":{"range":[[10,15],[10,16]]},"deserializer":"MarkerPatch"},{"oldRange":[[10,15],[10,16]],"newRange":[[10,15],[10,15]],"oldText":"'","newText":"","normalizeLineEndings":true,"markerPatches":{},"deserializer":"BufferPatch"},{"id":1,"oldParams":{"tailed":true},"newParams":{"tailed":false},"deserializer":"MarkerPatch"}],"deserializer":"Transaction"},{"patches":[{"oldRange":[[10,15],[10,15]],"newRange":[[10,15],[10,16]],"oldText":"","newText":"s","normalizeLineEndings":{},"markerPatches":{},"deserializer":"BufferPatch"}],"deserializer":"Transaction"},{"patches":[{"oldRange":[[10,16],[10,16]],"newRange":[[10,16],[10,17]],"oldText":"","newText":"a","normalizeLineEndings":{},"markerPatches":{},"deserializer":"BufferPatch"}],"deserializer":"Transaction"},{"patches":[{"oldRange":[[10,17],[10,17]],"newRange":[[10,17],[10,18]],"oldText":"","newText":"m","normalizeLineEndings":{},"markerPatches":{},"deserializer":"BufferPatch"}],"deserializer":"Transaction"},{"patches":[{"oldRange":[[10,18],[10,18]],"newRange":[[10,18],[10,19]],"oldText":"","newText":"f","normalizeLineEndings":{},"markerPatches":{},"deserializer":"BufferPatch"}],"deserializer":"Transaction"},{"patches":[{"oldRange":[[10,19],[10,19]],"newRange":[[10,19],[10,20]],"oldText":"","newText":"i","normalizeLineEndings":{},"markerPatches":{},"deserializer":"BufferPatch"}],"deserializer":"Transaction"},{"patches":[{"oldRange":[[10,20],[10,20]],"newRange":[[10,20],[10,21]],"oldText":"","newText":"l","normalizeLineEndings":{},"markerPatches":{},"deserializer":"BufferPatch"}],"deserializer":"Transaction"},{"patches":[{"oldRange":[[10,21],[10,21]],"newRange":[[10,21],[10,22]],"oldText":"","newText":"e","normalizeLineEndings":{},"markerPatches":{},"deserializer":"BufferPatch"}],"deserializer":"Transaction"},{"patches":[{"oldRange":[[5,46],[5,46]],"newRange":[[5,46],[6,0]],"oldText":"","newText":"\n","normalizeLineEndings":{},"markerPatches":{},"deserializer":"BufferPatch"},{"oldRange":[[6,0],[6,0]],"newRange":[[6,0],[6,0]],"oldText":"","newText":"","normalizeLineEndings":true,"markerPatches":{},"deserializer":"BufferPatch"}],"deserializer":"Transaction"},{"patches":[{"oldRange":[[6,0],[6,0]],"newRange":[[6,0],[6,33]],"oldText":"","newText":"pysam.sort( \"ex1.bam\", \"output\" )","normalizeLineEndings":{},"markerPatches":{},"deserializer":"BufferPatch"}],"deserializer":"Transaction"},{"patches":[{"id":1,"oldParams":{"tailed":true,"range":[[6,13],[6,16]]},"newParams":{"tailed":false,"range":[[6,16],[6,16]]},"deserializer":"MarkerPatch"},{"oldRange":[[6,13],[6,16]],"newRange":[[6,13],[6,14]],"oldText":"ex1","newText":"E","normalizeLineEndings":{},"markerPatches":{},"deserializer":"BufferPatch"}],"deserializer":"Transaction"},{"patches":[{"oldRange":[[6,14],[6,14]],"newRange":[[6,14],[6,15]],"oldText":"","newText":"x","normalizeLineEndings":{},"markerPatches":{},"deserializer":"BufferPatch"}],"deserializer":"Transaction"},{"patches":[{"oldRange":[[6,15],[6,15]],"newRange":[[6,15],[6,16]],"oldText":"","newText":"a","normalizeLineEndings":{},"markerPatches":{},"deserializer":"BufferPatch"}],"deserializer":"Transaction"},{"patches":[{"oldRange":[[6,16],[6,16]],"newRange":[[6,16],[6,17]],"oldText":"","newText":"m","normalizeLineEndings":{},"markerPatches":{},"deserializer":"BufferPatch"}],"deserializer":"Transaction"},{"patches":[{"oldRange":[[6,17],[6,17]],"newRange":[[6,17],[6,18]],"oldText":"","newText":"p","normalizeLineEndings":{},"markerPatches":{},"deserializer":"BufferPatch"}],"deserializer":"Transaction"},{"patches":[{"oldRange":[[6,18],[6,18]],"newRange":[[6,18],[6,19]],"oldText":"","newText":"l","normalizeLineEndings":{},"markerPatches":{},"deserializer":"BufferPatch"}],"deserializer":"Transaction"},{"patches":[{"oldRange":[[6,19],[6,19]],"newRange":[[6,19],[6,20]],"oldText":"","newText":"e","normalizeLineEndings":{},"markerPatches":{},"deserializer":"BufferPatch"}],"deserializer":"Transaction"},{"patches":[{"oldRange":[[11,0],[11,0]],"newRange":[[11,0],[11,1]],"oldText":"","newText":"#","normalizeLineEndings":{},"markerPatches":{},"deserializer":"BufferPatch"}],"deserializer":"Transaction"},{"patches":[{"id":1,"oldParams":{"tailed":true,"range":[[0,0],[12,0]]},"newParams":{"tailed":false,"range":[[0,0],[0,0]]},"deserializer":"MarkerPatch"},{"oldRange":[[0,0],[12,0]],"newRange":[[0,0],[31,13]],"oldText":"#!/usr/bin/python\nimport os\nimport pysam\n\n\nsamfile = pysam.Samfile( \"Example.bam\", \"rb\" )\npysam.sort( \"Example.bam\", \"output\" )\n\ndef my_fetch_callback( alignment ):\n    print str(alignment)\n\n#samfile.fetch( samfile, 10, 20, callback = my_fetch_callback )\n","newText":"#!/usr/bin/env python\nimport pysam\nimport argparse\nimport sys\n\nparser = argparse.ArgumentParser(description='Filter a paired-end BAM file such that both reads have MAPQs >= a threshold.')\nparser.add_argument('threshold', type=int, help=\"MAPQ threshold\")\nparser.add_argument('input_file', help=\"input file name\")\nparser.add_argument('output_file', help=\"output file name\")\nargs = parser.parse_args()\nif(args.threshold == None or args.input_file == None or args.output_file == None) :\n    parser.print_help()\n    sys.exit()\n\n#One could look at the file name too see if we're dealing with a SAM or BAM file, but this is simpler\nifile = pysam.Samfile(args.input_file, \"rb\")\nofile = pysam.Samfile(args.output_file, \"wb\", template=ifile)\n\n#iterate\nwhile(1) :\n    try :\n        r1 = ifile.next()\n        r2 = ifile.next()\n    except :\n        break\n\n    if(r1.mapq >= int(args.threshold) and r2.mapq >= int(args.threshold)) :\n        ofile.write(r1)\n        ofile.write(r2)\n\nifile.close()\nofile.close()","normalizeLineEndings":{},"markerPatches":{},"deserializer":"BufferPatch"},{"id":1,"oldParams":{"range":[[0,0],[0,0]]},"newParams":{"range":[[31,13],[31,13]]},"deserializer":"MarkerPatch"}],"deserializer":"Transaction"}],"redoStack":[],"deserializer":"History"},"filePath":"/Users/Rad/Documents/Scripts/test.py","modifiedWhenLastPersisted":false,"digestWhenLastPersisted":"2db46e445f468b657990d3fd02adcb9729b98a3c","deserializer":"TextBuffer"},{"text":"#from pipelines.io import make_directory, make_parent_directory\nfrom ruffus import *\nfrom ruffus.ruffus_utility import CHECKSUM_FILE_TIMESTAMPS\n\nimport argparse\nimport os,sys\nimport yaml\n\n#=======================================================================================================================\n# Read Command Line Input\n#=======================================================================================================================\n\n#parser = argparse.ArgumentParser()\n\n#parser.add_argument('config_file',\n                    #help='''Path to yaml config file.''')\n\n#parser.add_argument('--num_cpus', type=int, default=1,\n                    #help='''Number of cpus to use for the analysis. If set to -1 then as many cpus as samples will\n                    #be used. Default is 1.''')\n\n#parser.add_argument('--mode', choices=['local', 'cluster', 'printout'], default='printout',\n                    #help='''Mode to run the pipeline in. local will run the pipeline on the compute it was launched\n                    #from. cluster will submit the jobs to a cluster using SGE. printout shows which tasks will be\n                    #run. default is printout.''')\n\n#parser.add_argument('--install_dir', default=None,\n                    #help='''Path to local installation files to override system defaults.''')\n\n#args = parser.parse_args()\n\nfh = open(\"patient_10.config.yaml\")\n\nconfig = yaml.load(fh)\n\nfh.close()\n\n#=======================================================================================================================\n# Scripts\n#=======================================================================================================================\ncwd = os.path.dirname(os.path.realpath(__file__))\n\nbin_dir = os.path.join(cwd, 'bin')\n\nbuild_amplicon_positions_file_script = os.path.join(bin_dir, 'build_amplicon_positions_file.py')\n\ndo_binomial_exact_test_script = os.path.join(bin_dir, 'do_binomial_exact_test.py')\n\nbuild_results_file_script = os.path.join(bin_dir, 'build_results_file.py')\n\nbam_to_counts_script = os.path.join(bin_dir, 'bam_to_counts.py')\n\nrun_bwa_script = os.path.join(bin_dir, 'run_bwa_backtrack.sh')\n#run_bwa_script = os.path.join(bin_dir, 'run_bwa_mem_paired_end.sh')\n#run_bowtie2_script = os.path.join(bin_dir,'run_bowtie2.sh')\n\nmutation_seq_paired_samples_script = os.path.join(bin_dir, 'script')\n\nmutation_seq_single_sample_script  = os.path.join(bin_dir, 'script')\n\nconvert_vcf_to_tsv_script  = os.path.join(bin_dir, 'script')\n\nfilter_candidates_per_target_region_script =  os.path.join(bin_dir, 'script')\n\n#=======================================================================================================================\n# Set System Paths\n#=======================================================================================================================\n\n#=======================================================================================================================\n# Pipeline\n#=======================================================================================================================\ndef load_fastq_files():\n    for sample_id in config['samples']:\n        fastq_file_1 = config['samples'][sample_id]['fastq_file_1']\n\n        fastq_file_2 = config['samples'][sample_id]['fastq_file_2']\n\n        out_file = os.path.join(config['out_dir'], 'tmp', 'bam', '{0}.bam'.format(sample_id))\n\n        yield [[fastq_file_1, fastq_file_2], out_file, run_bwa_script]\n\n@files(load_fastq_files)\ndef align_fastq_files(in_files, out_file, script):\n    make_parent_directory(out_file)\n\n    cmd = 'sh'\n\n    cmd_args = [\n                script,\n                config['ref_genome'],\n                in_files[0],\n                in_files[1],\n                out_file\n                ]\n\n    run_cmd(cmd, cmd_args, mem=10, max_mem=20)\n\n# Injection of Discovery mode\n\n\nif 'normal_sample' in config:\n  discovery_mode = True\n  normal_sample = True\nelse:\n  discovery_mode = False\n  normal_sample = False\n\n\n@transform(align_fastq_files, suffix('.bam'), '.dedup.bam')\ndef deduplicate(in_file, out_file):\n    \"\"\"\n    Remove apparent duplicates from merged bams using Picard MarkDuplicates.\n    \"\"\"\n\n\n@active_if(discovery_mode)\n@transform(deduplicate, suffix('.dedup.bam'), '.intervals')\ndef create_targets(in_file,out_files):\n\n  cmd = 'java'\n  cmd_args = [\"-Xmx2g -jar GenomeAnalysisTK.jar\",\n             \"-T\",\"RealignerTargetCreator\",\n             \"-R\",config['reference'],\n             \"-I\",in_file,\n             \"-o\",out_file\n             ]\n\n  run_cmd[cmd,cmd_args]\n\n\n@transform(create_targets,suffix('.intervals'), add_inputs(r\"\\1.dedup.bam\"), '.realigned.bam')\ndef gatk_realignment(in_file,bam_file,out_file):\n\n  #bam_file = in_file.replace(\".intervals\",\".bam\")\n  cmd = 'java'\n\n  cmd_args = [\"-Xmx2g -jar GenomeAnalysisTK.jar\",\n             \"-T\",\"IndelRealigner\",\n             \"-R\",config['reference'],\n             \"-targetIntervals\",in_file,\n             \"-I\",bam_file,\n             \"-o\",out_file\n             ]\n\n  run_cmd[cmd,cmd_args]\n\n@transform(gatk_realignment, suffix('.realigned.bam'),'.realigned_recalibrated.bam')\ndef base_quality_recalibration(inputs, outputs):\n    \"\"\"\n    GATK CountCovariates, first step of base quality score recalibration.\n    \"\"\"\n\n@transform(base_quality_recalibration, suffix('.realigned_recalibrated.bam'), '.sorted.bam')\ndef sort_bam_file(bam_file, sorted_bam_file):\n    out_prefix = sorted_bam_file.replace(\".bam\", \"\")\n\n    cmd = 'samtools'\n\n    cmd_args = ['sort', bam_file, out_prefix]\n\n    run_cmd(cmd, cmd_args)\n\n@transform(sort_bam_file, suffix('.sorted.bam'), '.sorted.bam.bai')\ndef index_bam_file(bam_file, bai_file):\n    cmd = 'samtools'\n\n    cmd_args = ['index', bam_file]\n\n    run_cmd(cmd, cmd_args)\n\n\n# Variant Calling : paired samples\n\n@active_if(discovery_mode)\n@active_if(normal_sample)\n@follows(index_bam_file)\n@transform(sort_bam_file, regex(r'(.*)/bam/(.*)\\.sorted\\.bam'), r\"\\1/calls/\\2.vcf\" ,mutation_seq_paired_samples_script)\ndef call_variant_paired_samples(in_file,out_file,script):\n  '''\n  Runs mutation seq in paired samples mode\n  '''\n\n  make_parent_directory(out_file)\n  cmd = 'python'\n  cmd_args = [ script,\n               'normal:', config['normal_sample'],\n               'tumour:', in_file,\n               'reference:', config['reference'],\n               'model:', config['mutationseq_model'],\n               '--out', out_file,\n               '--config', config['mutation_seq_config']\n               ]\n  run_cmd[cmd,cmd_args]\n\n# Alternative : Variant Calling : single sample\n\n@active_if(discovery_mode)\n@active_if(normal_sample == False )\n@transform(sort_bam_file, regex(r'(.*)/bam/(.*)\\.sorted\\.bam'), r\"\\1/calls/\\2.vcf\" ,mutation_seq_single_sample_script)\ndef call_variant_single_sample(in_file,out_file,script):\n  '''\n  Runs mutation seq in single sample mode\n  (make sure about the exact command line to avoid typo)\n  '''\n\n\n  make_parent_directory(out_file)\n  cmd = 'python'\n  cmd_args = [ script,\n               'tumour:', in_file,\n               'reference:', config['reference'],\n               'model:', config['mutationseq_model'],\n               '--out', out_file,\n               '--config', config['mutation_seq_config']\n               ]\n  run_cmd[cmd,cmd_args]\n\n\n# Convert the VCF output into tsv files\n\n@transform([call_variant_single_sample,call_variant_paired_samples], regex(r'(.*)/calls/(.*)\\.vcf'), r\"\\1/candidates/\\2.candidates.tsv\",convert_vcf_to_tsv_script)\ndef create_target_candidates(in_file,out_file,script):\n  '''\n  This function is a converter (VCF to TAB) : watch this for the new pipeline factory\n  '''\n  make_parent_directory(out_file)\n  cmd = 'sh'\n  cmd_args = [script,in_file,out_file]\n  run_cmd[cmd,cmd_args]\n\n\n\n# Zoom into get the targets within the regions of interest\n# This is calling a new library to the pipeline\n# Quick fix : shell script to run bedtools, next version : python code using the python client for bedtools\n\n@transform(create_target_candidates, suffix(\".candidates.tsv\"), r\"\\1.filtered.candidates.tsv\", filter_candidates_per_target_region_script)\ndef filter_target_candidates(in_file,out_file,script):\n  '''\n  We now look into our regions of interest, take all calls, extract informations we need and create a position file\n  '''\n  make_parent_directory(out_file)\n  cmd = 'sh'\n  cmd_args = [script,in_file,out_file]\n  run_cmd[cmd,cmd_args]\n\n@merge(filter_target_candidates,config['positions_file'])\ndef merge_positions(in_file, out_file, script):\n  pass\n\n\n\n#@files(config['positions_file'],\n@files(merge_positions,\n       os.path.join(config['out_dir'], 'tmp', 'amplicon_positions', '{0}.tsv'.format(config['analysis_id'])))\ndef build_amplicon_positions_file(in_file, out_file):\n    make_parent_directory(out_file)\n\n    cmd = 'python'\n\n    cmd_args = [build_amplicon_positions_file_script, in_file, out_file]\n\n    run_cmd(cmd, cmd_args)\n\n@follows(index_bam_file, build_amplicon_positions_file)\n@transform(sort_bam_file,\n           regex(r'(.*)/bam/(.*)\\.sorted\\.bam'),\n           add_inputs(build_amplicon_positions_file),\n           r'\\1/counts/\\2.tsv',\n           bam_to_counts_script)\ndef build_counts_file(in_files, counts_file, script):\n    make_parent_directory(counts_file)\n\n    cmd = 'python'\n\n    bam_file = in_files[0]\n\n    positions_file = in_files[1]\n\n    cmd_args = [\n                script,\n                bam_file,\n                counts_file,\n                '--positions_file', positions_file,\n                '--count_duplicates',\n                '--min_bqual', config['min_bqual'],\n                '--min_mqual', config['min_mqual'],\n                '--ref_genome', config['ref_genome'],\n                '--ref_base',\n                '--var_base'\n                ]\n\n    run_cmd(cmd, cmd_args)\n\n@transform(build_counts_file, regex('(.*)/counts/(.*)\\.tsv'), r'\\1/variant_status/\\2.tsv')\ndef do_binomial_exact_test(in_file, out_file):\n    make_parent_directory(out_file)\n\n    cmd = 'python'\n\n    cmd_args = [\n                do_binomial_exact_test_script,\n                in_file,\n                config['positions_file'],\n                out_file,\n                '--family_wise_error_rate', config['family_wise_error_rate'],\n                '--low_coverage_threshold', config['low_coverage_threshold']\n                ]\n\n    run_cmd(cmd, cmd_args)\n\n@merge(do_binomial_exact_test, r'{0}/results/{1}.xls'.format(config['out_dir'], config['analysis_id']))\ndef build_summary_file(in_files, out_file):\n    make_parent_directory(out_file)\n\n    cmd = 'python'\n\n    cmd_args = [\n                build_results_file_script,\n                out_file\n                ]\n\n    sample_ids = [os.path.splitext(os.path.basename(file_name))[0] for file_name in in_files]\n\n    cmd_args.append('--sample_ids')\n    cmd_args.extend(sample_ids)\n\n    cmd_args.append('--variant_call_files')\n    cmd_args.extend(in_files)\n\n    if 'normal_sample' in config:\n        cmd_args.extend(['--normal_sample', config['normal_sample']])\n\n    run_cmd(cmd, cmd_args)\n\n@follows(build_summary_file)\ndef end():\n    pass\n\n#=======================================================================================================================\n# Run pipeline\n#=======================================================================================================================\ndef main():\n  #CHECKSUM_REGENERATE = 2\n  #pipeline_run(end, verbose = 5)\n  pipeline_printout(sys.stdout, end, verbose=4, wrap_width=200)\n  #pipeline_cleanup(cleanup_log = \"cleanup.log\")\n  pipeline_printout_graph (\"pipeline.png\", \"png\", end,test_all_task_for_update = True, user_colour_scheme = {\"colour_scheme_index\" :6})\n\nif __name__ == '__main__':\n    main()\n","markers":{"markers":{"1":{"id":1,"range":[[59,0],[59,0]],"tailed":false,"reversed":false,"valid":true,"invalidate":"never","persistent":true,"properties":{"type":"selection","editorId":187,"goalBufferRange":null},"deserializer":"Marker"}},"deserializer":"MarkerManager"},"history":{"undoStack":[],"redoStack":[],"deserializer":"History"},"filePath":"/Users/Rad/Documents/Scripts/test_python/pipeline.py","modifiedWhenLastPersisted":false,"digestWhenLastPersisted":"2b04ea6bfac819915854c5ff7b7684dd19345632","deserializer":"TextBuffer"},{"text":"from pipelines.io import make_directory, make_parent_directory\nfrom ruffus import *\nfrom ruffus.ruffus_utility import CHECKSUM_FILE_TIMESTAMPS\nfrom glob import *\nimport subprocess\nfrom subprocess import check_output\nfrom subprocess import Popen, PIPE\nimport argparse\nimport os,sys\nimport yaml\nimport time\nfrom termcolor import colored\nimport functools\n\n#=======================================================================================================================\n# Read Command Line Input\n#=======================================================================================================================\n\n\nparser = argparse.ArgumentParser(description='A python wrapper for GATK best practices guide (no variant call, just realignment)')\n\nparser.add_argument('--input_dir',\n                    help='''Input is a directory containing Bam files to be realigned''')\n\nparser.add_argument('--output_dir',\n                    help='''Output is a directory containing subfolders for targets, realignments, deduplicated bam files etc''')\n\nparser.add_argument('--config_file',\n                   help='''Path to yaml config file.''')\n\n\nparser.add_argument('--num_cpus', type=int, default=1,\n                    help='''Number of cpus to use for the analysis. If set to -1 then as many cpus as samples will\n                    be used. Default is 1.''')\n\nparser.add_argument('--mode', choices=['local', 'cluster', 'printout'], default='printout',\n                    help='''Mode to run the pipeline in. local will run the pipeline on the compute it was launched\n                    from. cluster will submit the jobs to a cluster using SGE. printout shows which tasks will be\n                    run. default is printout.''')\n\n\n\nargs = parser.parse_args()\n\n\nfh = open(args.config_file)\nconfig = yaml.load(fh)\nfh.close()\n\n\ngatk  = config['gatk']\npicard = config['picard']\nreference = config['reference']\ndbsnp  = config['dbsnp']\nindels = config['indels']\njava = config['java']\n\n\nmandatory_env = [gatk, picard, reference, dbsnp, indels, java]\n\n\ndef timer(stream=sys.stdout):\n    \"\"\"The timer decorator wraps a function and prints elapsed time to standard\n    out, or any other file-like object with a .write() method.\n    \"\"\"\n    def actual_timer(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Start the timer.\n            start = time.time()\n            # Run the decorated function.\n            ret = func(*args, **kwargs)\n            # Stop the timer.\n            end = time.time()\n            elapsed = end - start\n            name = func.__name__\n            stream.write(colored(\"{} took {} seconds\\n\".format(name, elapsed), 'red', attrs=['bold'] ))\n            # Return the decorated function's return value.\n            return ret\n        return wrapper\n    return actual_timer\n\n\ndef check_config_params():\n  for env in mandatory_env:\n    if env.__len__() == 0 :\n      print >> sys.stderr, \"It seems that one third party tool is not defined in the config file, please check your config file\"\n      sys.exit(1)\n\n\ndef success():\n  print >> sys.stderr , colored('   Task successfully finished   ', 'white', 'on_red', attrs=['blink'])\n\n\n\n#=======================================================================================================================\n# Start the Realignment pipeline\n#=======================================================================================================================\n\n\ncheck_config_params()\n\n\n@timer(sys.stderr)\n@posttask(success)\ndef load_bam_files():\n  #bam_files = glob(os.path.join(os.path.normpath(\".\",args.input_dir, '*.bam'))\n  for path,subdir,files in os.walk(args.input_dir):\n    for file in files :\n      if file.endswith(\".bam\"):\n        in_file = os.path.abspath(os.path.join(args.input_dir,file))\n        out_file = os.path.abspath(os.path.join(args.output_dir,\"bam/\",file)).replace(\".bam\",\".sorted.bam\")\n        yield [in_file,out_file]\n\n\n@posttask(success)\n@files(load_bam_files)\n@timer(sys.stderr)\ndef sort_mapped_reads(in_file, out_file):\n    '''\n    Sort the bam files using Samtools sort (room for using Picard)\n    '''\n\n\n    make_parent_directory(out_file)\n    #sort_recalibrated_alignment(in_file,out_file)\n    out_prefix = out_file.replace(\".bam\", \"\")\n    cmd = 'samtools'\n\n    cmd_args = ['sort', in_file, out_prefix]\n\n    run_cmd(cmd, cmd_args)\n\n\n\n@posttask(success)\n@transform(sort_mapped_reads, regex(r'(.*)/bam/(.*)\\.bam'), r\"\\1/dedup/\\2.dedup.bam\")\n@timer(sys.stderr)\ndef deduplicate(bam_sorted, bam_deduplicated):\n  '''\n  Remove PCR amplification identical reads\n  '''\n  #dedup(bam_duplicated, bam_deduplicated)\n\n  make_parent_directory(bam_deduplicated)\n\n  cmd = java\n  cmd_args = [\"-Xmx4g -jar\", os.path.join(picard,\"MarkDuplicates.jar\"),\n             ''.join([\"INPUT=\",bam_sorted]),\n             ''.join([\"OUTPUT=\",bam_deduplicated]),\n             \"METRICS_FILE=metrics.txt\"\n              ]\n  run_cmd(cmd,cmd_args)\n\n\n@posttask(success)\n@transform(deduplicate, regex(r'(.*)/dedup/(.*)\\.dedup\\.bam'), '.bai')\n@timer(sys.stderr)\ndef index_mapped_reads(in_file, out_file):\n    '''\n    Sort the bam files using Samtools sort (room for using Picard)\n    '''\n    #make_parent_directory(out_file)\n\n    #sort_recalibrated_alignment(in_file,out_file)\n    #out_prefix = out_file.replace(\".bam\", \"\")\n\n    cmd = 'samtools'\n\n    cmd_args = ['index', in_file]\n\n    run_cmd(cmd, cmd_args)\n\n\n@posttask(success)\n@follows(index_mapped_reads)\n@transform(deduplicate, regex(r'(.*)/dedup/(.*)\\.dedup\\.bam'), r'\\1/intervals/\\2.intervals')\n@timer(sys.stderr)\ndef create_targets(in_file, out_file):\n  '''\n  GATK RealignerTargetCreator : Create suspecious regions where a realignment will be done\n  '''\n\n  make_parent_directory(out_file)\n\n  #create_target(in_file,out_file)\n  cmd = java\n  cmd_args = [\"-Xmx4g -jar\", os.path.join(gatk,\"GenomeAnalysisTK.jar\"),\n             \"-T\",\"RealignerTargetCreator\",\n             \"-R\",config['reference'],\n             \"-I\",in_file,\n             \"-o\",out_file\n             ]\n\n  run_cmd(cmd, cmd_args)\n\n\n\n\n@posttask(success)\n@transform(create_targets, regex(r'(.*)/intervals/(.*)\\.intervals'), add_inputs(r'\\1/dedup/\\2.dedup.bam'),r'\\1/realigned/\\2.realigned.bam')\n@timer(sys.stderr)\ndef realign(in_files, out_file):\n  '''\n  GATK IndelRealigner\n  '''\n  #realign(in_file,out_file)\n\n  make_parent_directory(out_file)\n\n  cmd = java\n\n  cmd_args = [\"-Xmx4g -jar\", os.path.join(gatk,\"GenomeAnalysisTK.jar\"),\n           \"-T\",\"IndelRealigner\",\n           \"-R\",config['reference'],\n           \"-targetIntervals\",in_files[0],\n           \"-I\",in_files[1],\n           \"-o\",out_file\n           ]\n  run_cmd(cmd, cmd_args)\n\n\n\n@posttask(success)\n@transform(realign,regex(r'(.*)/realigned/(.*)\\.realigned\\.bam'),r'\\1/realigned/\\2.realigned.grp')\n@timer(sys.stderr)\ndef base_quality_recalibrator_pre(in_file, out_file):\n  '''\n  GATK recalibrate 1\n\n  '''\n  #recalibrate(in_file, out_file)\n\n  cmd = java\n\n  cmd_args = [\"-Xmx4g -jar\", os.path.join(gatk,\"GenomeAnalysisTK.jar\"),\n             \"-T\",\"BaseRecalibrator\",\n             \"-R\",config['reference'],\n             \"-knownSites\", config['dbsnp'],\n #            \"-knownSites\", config['indels'],\n             \"-I\",in_file,\n             \"-o\",out_file,\n             #\"-plots\",\"recal.grp.pdf\"\n             ]\n\n  run_cmd(cmd, cmd_args)\n\n\n\n@posttask(success)\n@follows(base_quality_recalibrator_pre)\n@transform(realign,regex(r'(.*)/realigned/(.*)\\.realigned\\.bam'), add_inputs(r'\\1/realigned/\\2.realigned.grp') , r'\\1/realigned/\\2.post_recal.grp2')\n@timer(sys.stderr)\ndef base_quality_recalibrator_post(in_files, out_file):\n  '''\n  GATK recalibrate 2nd step\n  '''\n  #recalibrate(in_file, out_file)\n\n  cmd = java\n\n  cmd_args = [\"-Xmx4g -jar\", os.path.join(gatk,\"GenomeAnalysisTK.jar\"),\n             \"-T\",\"BaseRecalibrator\",\n             \"-R\",config['reference'],\n             \"-I\",in_files[0],\n             \"-BQSR\", in_files[1],\n             \"-knownSites\", config['dbsnp'],\n             \"-o\",out_file,\n             #\"-plots\",\"post_recal.grp.pdf\"\n             ]\n\n  run_cmd(cmd, cmd_args)\n\n\n\n\n\n@posttask(success)\n@follows(base_quality_recalibrator_post)\n@transform(base_quality_recalibrator_pre, regex(r'(.*)/realigned/(.*)\\.grp'), add_inputs(r'\\1/realigned/\\2.bam'),r'\\1/realigned/\\2.recalibrated.bam')\n@timer(sys.stderr)\ndef print_reads(in_files, out_file):\n  '''\n  GATK Get the recalibrated alignment\n  '''\n  #print_reads(in_file,out_file)\n\n  cmd = java\n\n  cmd_args = [\"-Xmx4g -jar\", os.path.join(gatk,\"GenomeAnalysisTK.jar\"),\n             \"-T\",\"PrintReads\",\n             \"-R\",config['reference'],\n             \"-I\",in_files[1],\n             \"-BQSR\", in_files[0],\n             \"-o\",out_file\n             ]\n\n  run_cmd(cmd, cmd_args)\n\n\n\n\n@posttask(success)\n@transform(print_reads, regex(r'(.*)/realigned/(.*)\\.recalibrated\\.bam'),r'\\1/realigned/\\2.sorted.bam')\n@timer(sys.stderr)\ndef sort_recalibrated_bams(in_file, out_file):\n  '''\n  Sort the bam files using Samtools sort (room for using Picard)\n  '''\n  #sort_recalibrated_alignment(in_file,out_file)\n\n  out_prefix = out_file.replace(\".bam\",\"\")\n  cmd = 'samtools'\n\n  cmd_args = ['sort', in_file, out_prefix]\n\n  run_cmd(cmd, cmd_args)\n\n\n\n\n@posttask(success)\n@transform(sort_recalibrated_bams,regex(r'(.*)/realigned/(.*)\\.sorted\\.bam'),r'\\1/realigned/\\2.sorted.indexed.bam')\n@timer(sys.stderr)\ndef index_recalibrated_bams(in_file, out_file):\n  '''\n  Index the bam files using Samtools index (room for using Picard)\n  '''\n  #index_recalibrated_alignment(in_file,out_file)\n\n  cmd = 'samtools'\n\n  cmd_args = ['index', in_file]\n\n  run_cmd(cmd, cmd_args)\n\n\n\n@follows(index_recalibrated_bams)\ndef end():\n    pass\n\n\n\n#=======================================================================================================================\n# Run pipeline\n#=======================================================================================================================\nif args.mode in ['cluster', 'local']:\n    if args.mode == 'cluster':\n        from pipelines.job_manager import ClusterJobManager\n\n        import datetime\n\n        log_dir = os.path.join(config['log_dir'], 'log', datetime.datetime.now().isoformat(','))\n\n        job_manager = ClusterJobManager(log_dir)\n\n    elif args.mode == 'local':\n        from pipelines.job_manager import LocalJobManager\n\n        job_manager = LocalJobManager()\n\n    run_cmd = job_manager.run_job\n\n    try:\n#        pipeline_run([base_quality_recalibrator_post,print_reads,sort_recalibrated_bams,index_recalibrated_bams], multiprocess=args.num_cpus) #, use_multi_threading=True)\n       \tpipeline_run(end, multithread=args.num_cpus, checksum_level=CHECKSUM_FILE_TIMESTAMPS)\n\n\n    finally:\n        job_manager.close()\n\nelif args.mode == 'printout':\n    import sys\n\n    pipeline_printout(sys.stdout, end, verbose=3, wrap_width=200)\n","markers":{"markers":{"1":{"id":1,"range":[[20,0],[20,0]],"tailed":false,"reversed":true,"valid":true,"invalidate":"never","persistent":true,"properties":{"type":"selection","editorId":250,"goalBufferRange":null},"deserializer":"Marker"}},"deserializer":"MarkerManager"},"history":{"undoStack":[{"patches":[{"id":1,"oldParams":{"tailed":true,"range":[[19,0],[20,0]]},"newParams":{"tailed":false,"range":[[20,0],[20,0]]},"deserializer":"MarkerPatch"},{"oldRange":[[19,0],[20,0]],"newRange":[[19,0],[20,0]],"oldText":"parser = argparse.ArgumentParser()\n","newText":"parser = argparse.ArgumentParser(description='A python wrapper for GATK best practices guide (no variant call, just realignment)')\n","normalizeLineEndings":{},"markerPatches":{},"deserializer":"BufferPatch"}],"deserializer":"Transaction"},{"patches":[{"id":1,"oldParams":{"tailed":false},"newParams":{"tailed":true},"deserializer":"MarkerPatch"},{"id":1,"oldParams":{"reversed":false,"range":[[20,0],[20,0]]},"newParams":{"reversed":true,"range":[[19,130],[20,0]]},"deserializer":"MarkerPatch"},{"oldRange":[[19,130],[20,0]],"newRange":[[19,130],[19,130]],"oldText":"\n","newText":"","normalizeLineEndings":true,"markerPatches":{},"deserializer":"BufferPatch"},{"id":1,"oldParams":{"tailed":true},"newParams":{"tailed":false},"deserializer":"MarkerPatch"}],"deserializer":"Transaction"}],"redoStack":[],"deserializer":"History"},"filePath":"/Users/Rad/Documents/Scripts/indel_realignment_pipeline/realign.py","modifiedWhenLastPersisted":false,"digestWhenLastPersisted":"6ce5d9269a65a06fddd9a6334d9bb9040a4c92a8","deserializer":"TextBuffer"}],"deserializer":"Project"},"workspace":{"paneContainer":{"root":{"items":[{"id":75,"softTabs":true,"displayBuffer":{"id":76,"softWrap":false,"editorWidthInChars":136,"scrollTop":454,"scrollLeft":0,"tokenizedBuffer":{"bufferPath":"/Users/Rad/Documents/Scripts/test.py","tabLength":4,"deserializer":"TokenizedBuffer"},"deserializer":"DisplayBuffer"},"deserializer":"Editor"},{"id":187,"softTabs":true,"displayBuffer":{"id":188,"softWrap":false,"editorWidthInChars":139,"scrollTop":1467,"scrollLeft":0,"tokenizedBuffer":{"bufferPath":"/Users/Rad/Documents/Scripts/test_python/pipeline.py","tabLength":4,"deserializer":"TokenizedBuffer"},"deserializer":"DisplayBuffer"},"deserializer":"Editor"},{"id":250,"softTabs":true,"displayBuffer":{"id":251,"softWrap":false,"editorWidthInChars":137,"scrollTop":3692,"scrollLeft":0,"tokenizedBuffer":{"bufferPath":"/Users/Rad/Documents/Scripts/indel_realignment_pipeline/realign.py","tabLength":2,"deserializer":"TokenizedBuffer"},"deserializer":"DisplayBuffer"},"deserializer":"Editor"}],"activeItemUri":"/Users/Rad/Documents/Scripts/indel_realignment_pipeline/realign.py","focused":false,"active":true,"deserializer":"Pane"},"deserializer":"PaneContainer"},"fullScreen":false,"deserializer":"Workspace"},"packageStates":{"script":{"scriptOptionsViewState":""},"find-and-replace":{"viewState":{"findHistory":["rows","chr"],"replaceHistory":[],"modelState":{"useRegex":false,"inCurrentSelection":false,"caseSensitive":false}}},"fuzzy-finder":{"/Users/Rad/Documents/Scripts/test.py":1401299124521,"/Users/Rad/Documents/Scripts/test_python/pipeline.py":1401300853054,"/Users/Rad/Documents/Scripts/indel_realignment_pipeline/realign.py":1401301003945},"keybinding-resolver":{"attached":false},"metrics":{"sessionLength":146644114},"tree-view":{"directoryExpansionStates":{"indel_realignment_pipeline":{}},"selectedPath":"/Users/Rad/Documents/Scripts/indel_realignment","hasFocus":true,"attached":true,"scrollLeft":0,"scrollTop":0,"width":273},"gist-it":{}}}